{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "cMK0kw0myLFQ",
    "outputId": "41a4b414-ccff-4157-cd51-bba0cfcf6ed5"
   },
   "source": [
    "# Introduction\n",
    "In this notebook, we'll focus on data wrangling. Let's outline the steps and the goals of each step.\n",
    "\n",
    "|Step               |Goal                                                                   |\n",
    "|-------------------|-----------------------------------------------------------------------|\n",
    "|Data Collection    |Gather and join the data to streamline the next steps of the capstone  |\n",
    "|Data Organization: |Establish the file structure and version control                       |\n",
    "|Data Definition:   |Understand, annotate and clean the data in preparation for future work |\n",
    "|Data Cleaning:     |Check for missing data or wrong data, and handle them appropriately    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SmcYZLty2z8"
   },
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60Bl9Fvc9mho"
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "We'll import the data from Kaggle. \n",
    "\n",
    "Kaggle requires users to sign in and generate an API Key. Make sure your API key is at the correct location before running the next cell. If necessary, also make sure that Kaggle has been installed before continuing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "riiid-test-answer-prediction.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "# Download the zipped data using the Kaggle API \n",
    "!kaggle competitions download -c riiid-test-answer-prediction -p \"..\\data\\raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unzip the downloaded file\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "\n",
    "zipped_data_path = Path('../data/raw/riiid-test-answer-prediction.zip')\n",
    "unzip_destination_folder_path = Path('../data/interim')\n",
    "\n",
    "with ZipFile(zipped_data_path, 'r') as zf:\n",
    "    # Save list of file names in zip file to a list\n",
    "    zf_names = zf.namelist()\n",
    "    # Extract all files\n",
    "    zf.extractall(unzip_destination_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example_sample_submission.csv',\n",
       " 'example_test.csv',\n",
       " 'lectures.csv',\n",
       " 'questions.csv',\n",
       " 'riiideducation/__init__.py',\n",
       " 'riiideducation/competition.cpython-37m-x86_64-linux-gnu.so',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the names of the unzipped files for the file names containing our data.\n",
    "zf_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data_csv_files are  `lectures.csv`,  `questions.csv`, `train.csv` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Mg3QVJ5x0KxU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Define data paths\n",
    "lectures_csv_path = Path('../data/interim/lectures.csv')\n",
    "questions_csv_path = Path('../data/interim/questions.csv')\n",
    "train_csv_path = Path('../data/interim/train.csv')\n",
    "\n",
    "# For these small csv files, import them directly with pandas.read_csv()\n",
    "df_lectures = pd.read_csv(lectures_csv_path)\n",
    "df_questions = pd.read_csv(questions_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train.csv` is a large csv file, over 7 GB and 100M rows, so we need to load it in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make DataFrame generator from CSV in chunks\n",
    "df_generator = pd.read_csv(train_csv_path, chunksize=10000000)\n",
    "\n",
    "#Initialize an empty DataFrame: df_train\n",
    "df_train = pd.DataFrame()\n",
    "\n",
    "# Iterate over each DataFrame chunk\n",
    "for df_chunk in df_generator:\n",
    "    df_train = df_train.append(df_chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing as a dataframe, save the dataframe as a binary file, so that we can quickly reload the dataframe and resume.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BVwjKHLt8-o1"
   },
   "outputs": [],
   "source": [
    "# Define paths\n",
    "lectures_pkl_path = Path('../data/interim/lectures.pkl.gzip')\n",
    "questions_pkl_path = Path('../data/interim/questions.pkl.gzip')\n",
    "train_pkl_path = Path('../data/interim/train.pkl.gzip')\n",
    "\n",
    "# Save DataFrames to as pkl\n",
    "df_lectures.to_pickle(lectures_pkl_path)\n",
    "df_questions.to_pickle(questions_pkl_path)\n",
    "df_train.to_pickle(train_pkl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the heads of the three DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lecture_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>part</th>\n",
       "      <th>type_of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>185</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192</td>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "      <td>solving question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>317</td>\n",
       "      <td>156</td>\n",
       "      <td>5</td>\n",
       "      <td>solving question</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lecture_id  tag part           type_of\n",
       "0         89  159    5           concept\n",
       "1        100   70    1           concept\n",
       "2        185   45    6           concept\n",
       "3        192   79    5  solving question\n",
       "4        317  156    5  solving question"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lectures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51 131 162 38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131 36 81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131 101 162 92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131 149 162 29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>131 5 162 38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_id bundle_id correct_answer part            tags\n",
       "0           0         0              0    1   51 131 162 38\n",
       "1           1         1              1    1       131 36 81\n",
       "2           2         2              0    1  131 101 162 92\n",
       "3           3         3              0    1  131 149 162 29\n",
       "4           4         4              3    1    131 5 162 38"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56943</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>118363</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>131167</td>\n",
       "      <td>115</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>137965</td>\n",
       "      <td>115</td>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id  timestamp user_id content_id content_type_id task_container_id  \\\n",
       "0      0          0     115       5692               0                 1   \n",
       "1      1      56943     115       5716               0                 2   \n",
       "2      2     118363     115        128               0                 0   \n",
       "3      3     131167     115       7860               0                 3   \n",
       "4      4     137965     115       7922               0                 4   \n",
       "\n",
       "  user_answer answered_correctly  prior_question_elapsed_time  \\\n",
       "0           3                  1                          NaN   \n",
       "1           2                  1                      37000.0   \n",
       "2           0                  1                      55000.0   \n",
       "3           0                  1                      19000.0   \n",
       "4           1                  1                      11000.0   \n",
       "\n",
       "  prior_question_had_explanation  \n",
       "0                            NaN  \n",
       "1                          False  \n",
       "2                          False  \n",
       "3                          False  \n",
       "4                          False  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "et-SnDv39rpq"
   },
   "source": [
    "## Data Joining\n",
    "\n",
    "The data is available as one large file. So their is no need to join the data other than joining the chunks of the large file while importing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Subsetting with the larger dataframes\n",
    "As the data is quite large, it might be useful to subset the data during exploratory data analysis to speed up the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the row skip logic\n",
    "\n",
    "#Skip rows from based on condition like skip every 10th line\n",
    "def skip_all_but_nth_rows(n, idx):\n",
    "  return (idx % n != 0)\n",
    "  \n",
    "#Skip random lines  \n",
    "import random\n",
    "def rand_1_in_n(n, idx):\n",
    "  return True if random.randrange(1,n)==1 else False\n",
    "\n",
    "\n",
    "#Create the subsets \n",
    "\n",
    "#Define a Dataframe with 1/10 of the data\n",
    "df_train_1_10 = df_train[df_train.index % 10 == 0]\n",
    "\n",
    "#Define a DataFrame with 1/100 of the data\n",
    "df_train_1_100 = df_train[df_train.index % 100 == 0]\n",
    "\n",
    "#Define a DataFrame with 1/1000 of the data\n",
    "df_train_1_1000 = df_train[df_train.index % 1000 == 0]\n",
    "\n",
    "#Define a Dataframe with 1/10000 of the data\n",
    "df_train_1_10000 = df_train[df_train.index % 10000 == 0]\n",
    "\n",
    "#Define a Dataframe with 1/100000 of the data\n",
    "df_train_1_100000 = df_train[df_train.index % 100000 == 0]\n",
    "\n",
    "#Define a Dataframe with 1/1000000 of the data\n",
    "df_train_1_1000000 = df_train[df_train.index % 1000000 == 0]\n",
    "\n",
    "#Define a Dataframe with 1/10000000 of the data\n",
    "df_train_1_10000000 = df_train[df_train.index % 10000000 == 0]\n",
    "\n",
    "\n",
    "#Define subset paths\n",
    "train_pkl_path_1_10 = Path('../data/interim/train_1_10.pkl.gzip')\n",
    "train_pkl_path_1_100 = Path('../data/interim/train_1_100.pkl.gzip')\n",
    "train_pkl_path_1_1000 = Path('../data/interim/train_1_1000.pkl.gzip')\n",
    "train_pkl_path_1_10000 = Path('../data/interim/train_1_10000.pkl.gzip')\n",
    "train_pkl_path_1_100000 = Path('../data/interim/train_1_100000.pkl.gzip')\n",
    "train_pkl_path_1_1000000 = Path('../data/interim/train_1_1000000.pkl.gzip')\n",
    "train_pkl_path_1_10000000 = Path('../data/interim/train_1_10000000.pkl.gzip')\n",
    "\n",
    "#Save subset dataframes to pkl\n",
    "df_train_1_10.to_pickle(train_pkl_path_1_10)\n",
    "df_train_1_100.to_pickle(train_pkl_path_1_100)\n",
    "df_train_1_1000.to_pickle(train_pkl_path_1_1000)\n",
    "df_train_1_10000.to_pickle(train_pkl_path_1_10000)\n",
    "df_train_1_100000.to_pickle(train_pkl_path_1_100000)\n",
    "df_train_1_1000000.to_pickle(train_pkl_path_1_1000000)\n",
    "df_train_1_10000000.to_pickle(train_pkl_path_1_10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resuming data analysis without reimporting data from source files\n",
    "After the binary files have been saved, we can quickly resume by loading the binary files rather tha downloading, unzipping, and reading the csv files in chunks, again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((418, 4), (13523, 5), (101230332, 10))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "lectures_pkl_path = Path('../data/interim/lectures.pkl.gzip')\n",
    "questions_pkl_path = Path('../data/interim/questions.pkl.gzip')\n",
    "train_pkl_path = Path('../data/interim/train.pkl.gzip')\n",
    "\n",
    "with open(lectures_pkl_path, 'rb') as f:\n",
    "    df_lectures = pickle.load(f)\n",
    "    \n",
    "with open(questions_pkl_path, 'rb') as f:\n",
    "    df_questions = pickle.load(f)\n",
    "    \n",
    "with open(train_pkl_path, 'rb') as f:\n",
    "    df_train = pickle.load(f)\n",
    "    \n",
    "# Check the shape of the dataframes\n",
    "df_lectures.shape, df_questions.shape, df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the subsets from the pkl files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10123034, 10), (1012304, 10), (101231, 10))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define subset paths\n",
    "train_pkl_path_1_10 = Path('../data/interim/train_1_10.pkl.gzip')\n",
    "train_pkl_path_1_100 = Path('../data/interim/train_1_100.pkl.gzip')\n",
    "train_pkl_path_1_1000 = Path('../data/interim/train_1_1000.pkl.gzip')\n",
    "train_pkl_path_1_10000 = Path('../data/interim/train_1_10000.pkl.gzip')\n",
    "train_pkl_path_1_100000 = Path('../data/interim/train_1_100000.pkl.gzip')\n",
    "train_pkl_path_1_1000000 = Path('../data/interim/train_1_1000000.pkl.gzip')\n",
    "train_pkl_path_1_10000000 = Path('../data/interim/train_1_10000000.pkl.gzip')\n",
    "\n",
    "#Load the subsets\n",
    "with open( train_pkl_path_1_10, 'rb') as f:\n",
    "  df_train_1_10 = pickle.load(f)\n",
    "with open( train_pkl_path_1_100, 'rb') as f:\n",
    "  df_train_1_100 = pickle.load(f)\n",
    "with open( train_pkl_path_1_1000, 'rb') as f:\n",
    "  df_train_1_1000 = pickle.load(f)\n",
    "with open( train_pkl_path_1_10000, 'rb') as f:\n",
    "  df_train_1_10000 = pickle.load(f)\n",
    "with open( train_pkl_path_1_100000, 'rb') as f:\n",
    "  df_train_1_100000 = pickle.load(f)\n",
    "with open( train_pkl_path_1_1000000, 'rb') as f:\n",
    "  df_train_1_1000000 = pickle.load(f)\n",
    "with open( train_pkl_path_1_10000000, 'rb') as f:\n",
    "  df_train_1_10000000 = pickle.load(f)\n",
    "\n",
    "# Store a list of the subset DataFrames\n",
    "df_train_subsets = [df_train_1_10, \n",
    "                    df_train_1_100, \n",
    "                    df_train_1_1000,\n",
    "                    df_train_1_10000,\n",
    "                    df_train_1_100000,\n",
    "                    df_train_1_1000000,\n",
    "                    df_train_1_10000000,]\n",
    "\n",
    "# Check the shape of the subset dataframes\n",
    "df_train_1_10.shape, df_train_1_100.shape, df_train_1_1000.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGc2jua1y44z"
   },
   "source": [
    "# Data Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TdU2Vg0y7ek"
   },
   "source": [
    "## File Structure\n",
    "\n",
    "We'll use the default [file structure template for data science from cookiecutter data science](https://medium.com/@rrfd/cookiecutter-data-science-organize-your-projects-atom-and-jupyter-2be7862f487e).\n",
    "\n",
    "The data files have already been imported according to this template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FxQEMlbTb9p"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "|             |                  |\n",
    "|-------------|------------------|\n",
    "|├── README.md|          <- Front page of the project. Let everyone |\n",
    "|│|                         know the major points.|\n",
    "|│|\n",
    "|├── models|             <- Trained and serialized models, model|\n",
    "|│|                         predictions, or model summaries.|\n",
    "|│|\n",
    "|├── notebooks|          <- Jupyter notebooks. Use set naming|\n",
    "|│|                         E.g. `1.2-rd-data-exploration`.|\n",
    "|│|\n",
    "|├── reports|            <- HTML, PDF, and LaTeX.|\n",
    "|│   └── figures|        <- Generated figures.|\n",
    "|│|\n",
    "|├── requirements.txt|   <- File for reproducing the environment|\n",
    "|│|                         `$ pip freeze > requirements.txt`|\n",
    "|├── data|\n",
    "|│   ├── external|       <- Third party sources.|\n",
    "|│   ├── interim|        <- In-progress intermediate data.|\n",
    "|│   ├── processed|      <- The final data sets for modelling.|\n",
    "|│   └── raw|            <- The original, immutable data.|\n",
    "|│|\n",
    "|└── src |               <- Source code for use in this project.|\n",
    "|    ├── __init__.py|    <- Makes src a Python module. |\n",
    "|    │|\n",
    "|    ├── custom_func.py| <- Various custom functions to import.|\n",
    "|    │|\n",
    "|    ├── data          | <- Scripts to download or generate data.|\n",
    "|    │   └── make_dataset.py|\n",
    "|    │|\n",
    "|    ├── features|       <- Scripts raw data into features for|\n",
    "|    │   │        |         modeling.|\n",
    "|    │   └── build_features.py|\n",
    "|    │|\n",
    "|    ├── models|         <- Scripts to train models and then use|\n",
    "|    │   │     |            trained models to make predictions.|\n",
    "|    │   │     |            \n",
    "|    │   ├── predict_model.py|\n",
    "|    │   └── train_model.py|\n",
    "|    │|\n",
    "|    └── viz|            <- Scripts to create visualizations.|            \n",
    "|        └── viz.py|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version Control\n",
    "\n",
    "This notebook and it's related files will be stored in a local repository and on Github at:\n",
    "https://github.com/allen44/capstone-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environmental variables\n",
    "Following the best practices outlined in the [Twelve Factor App](https://12factor.net/), environmental variables will be excluded from version control.\n",
    "\n",
    "FOr this notebook, that means that any user wishing to reproduce the data loading steps will need their own Kaggle API key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kSKgl3FzAIu"
   },
   "source": [
    "# Data Definition\n",
    "\n",
    "Kaggle lists the definitions of the data on the [competition webpage](https://www.kaggle.com/c/riiid-test-answer-prediction/data).\n",
    "\n",
    "Here's a excerpt of the relevant section:\n",
    "\n",
    "\n",
    "### lectures.csv: metadata for the lectures watched by users as they progress in their education.\n",
    ">`lecture_id`: foreign key for the train/test content_id column, when the content type is lecture (1).\n",
    "\n",
    ">`part`: top level category code for the lecture.\n",
    "\n",
    ">`tag`: one tag codes for the lecture. The meaning of the tags will not be provided, but these codes are sufficient for clustering the lectures together.\n",
    "\n",
    ">`type_of`: brief description of the core purpose of the lecture\n",
    "\n",
    "### questions.csv: metadata for the questions posed to users.\n",
    ">`question_id`: foreign key for the train/test content_id column, when the content type is question (0).\n",
    "\n",
    ">`bundle_id`: code for which questions are served together.\n",
    "\n",
    ">`correct_answer`: the answer to the question. Can be compared with the train user_answer column to check if the user was right.\n",
    "\n",
    ">`part`: the relevant section of the TOEIC test.\n",
    "\n",
    ">`tags`: one or more detailed tag codes for the question. The meaning of the tags will not be provided, but these codes are sufficient for clustering the questions together.\n",
    "\n",
    "### train.csv \n",
    ">`content_id`: (int16) ID code for the user interaction\n",
    "\n",
    ">`content_type_id`: (int8) 0 if the event was a question being posed to the user, 1 if the event was the user watching a lecture.\n",
    "\n",
    ">`task_container_id`: (int16) Id code for the batch of questions or lectures. For example, a user might see three questions in a row before seeing the explanations for any of them. Those three would all share a task_container_id.\n",
    "\n",
    ">`user_answer`: (int8) the user's answer to the question, if any. Read -1 as null, for lectures.\n",
    "\n",
    ">`answered_correctly`: (int8) if the user responded correctly. Read -1 as null, for lectures.\n",
    "\n",
    ">`prior_question_elapsed_time`: (float32) The average time in milliseconds it took a user to answer each question in the previous question bundle, ignoring any lectures in between. Is null for a user's first question bundle or lecture. Note that the time is the average time a user took to solve each question in the previous bundle.\n",
    "\n",
    ">`prior_question_had_explanation`: (bool) Whether or not the user saw an explanation and the correct response(s) after answering the previous question bundle, ignoring any lectures in between. The value is shared across a single question bundle, and is null for a user's first question bundle or lecture. Typically the first several questions a user sees were part of an onboarding diagnostic test where they did not get any feedback.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the dtypes\n",
    "\n",
    "Based on the Kaggle eplanatoins of the data columns, we have enough info to set the dtypes on the DataFrames, and label missing or null data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_lectures\n",
      " lecture_id     int64\n",
      "tag            int64\n",
      "part           int64\n",
      "type_of       object\n",
      "dtype: object \n",
      "\n",
      "df_questions\n",
      " question_id        int64\n",
      "bundle_id          int64\n",
      "correct_answer     int64\n",
      "part               int64\n",
      "tags              object\n",
      "dtype: object \n",
      "\n",
      "df_train\n",
      " row_id                              int64\n",
      "timestamp                           int64\n",
      "user_id                             int64\n",
      "content_id                          int64\n",
      "content_type_id                     int64\n",
      "task_container_id                   int64\n",
      "user_answer                         int64\n",
      "answered_correctly                  int64\n",
      "prior_question_elapsed_time       float64\n",
      "prior_question_had_explanation     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Check current dtypes\n",
    "print('df_lectures\\n', df_lectures.dtypes, '\\n')\n",
    "print('df_questions\\n', df_questions.dtypes,  '\\n')\n",
    "print('df_train\\n', df_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the dtypes don't match the data as described by the Kaggle data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new dtypes\n",
    "lectures_dtypes = {'lecture_id': 'category',\n",
    "                    'part': 'category',\n",
    "                    'tag': 'category',\n",
    "                    'type_of': 'string'}\n",
    "            \n",
    "questions_dtypes = {'question_id': 'category', \n",
    "                   'bundle_id': 'category',\n",
    "                   'correct_answer': 'category', \n",
    "                   'part': 'category',\n",
    "                   'tags': 'string'}\n",
    "            \n",
    "train_dtypes = {'row_id': 'category',\n",
    "                'timestamp': 'int64',\n",
    "                'user_id': 'category',\n",
    "                'content_id': 'category', \n",
    "                'content_type_id': 'category',\n",
    "                'task_container_id': 'category', \n",
    "                'user_answer': 'category',\n",
    "                'answered_correctly': 'category',\n",
    "                'prior_question_elapsed_time': 'float',\n",
    "                'prior_question_had_explanation': 'category'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_lectures\n",
      " lecture_id    category\n",
      "tag           category\n",
      "part          category\n",
      "type_of         string\n",
      "dtype: object \n",
      "\n",
      "df_questions\n",
      " question_id       category\n",
      "bundle_id         category\n",
      "correct_answer    category\n",
      "part              category\n",
      "tags                string\n",
      "dtype: object \n",
      "\n",
      "df_train\n",
      " row_id                            category\n",
      "timestamp                            int64\n",
      "user_id                           category\n",
      "content_id                        category\n",
      "content_type_id                   category\n",
      "task_container_id                 category\n",
      "user_answer                       category\n",
      "answered_correctly                category\n",
      "prior_question_elapsed_time        float64\n",
      "prior_question_had_explanation    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Set the dtypes\n",
    "df_lectures = df_lectures.astype(lectures_dtypes)\n",
    "df_questions = df_questions.astype(questions_dtypes)\n",
    "df_train = df_train.astype(train_dtypes)\n",
    "\n",
    "#Check the new dtypes\n",
    "print('df_lectures\\n', df_lectures.dtypes, '\\n')\n",
    "print('df_questions\\n', df_questions.dtypes,  '\\n')\n",
    "print('df_train\\n', df_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_1_10: \n",
      " row_id                            category\n",
      "timestamp                            int64\n",
      "user_id                           category\n",
      "content_id                        category\n",
      "content_type_id                   category\n",
      "task_container_id                 category\n",
      "user_answer                       category\n",
      "answered_correctly                category\n",
      "prior_question_elapsed_time        float64\n",
      "prior_question_had_explanation    category\n",
      "dtype: object\n",
      "df_train_1_1000: \n",
      " row_id                            category\n",
      "timestamp                            int64\n",
      "user_id                           category\n",
      "content_id                        category\n",
      "content_type_id                   category\n",
      "task_container_id                 category\n",
      "user_answer                       category\n",
      "answered_correctly                category\n",
      "prior_question_elapsed_time        float64\n",
      "prior_question_had_explanation    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Also, set the dtypes on train subset DataFrames\n",
    "df_train_1_10 = df_train_1_10.astype(train_dtypes)\n",
    "df_train_1_100 = df_train_1_100.astype(train_dtypes)\n",
    "df_train_1_1000 = df_train_1_1000.astype(train_dtypes)\n",
    "df_train_1_10000 = df_train_1_10000.astype(train_dtypes)\n",
    "df_train_1_100000 = df_train_1_100000.astype(train_dtypes)\n",
    "df_train_1_1000000 = df_train_1_1000000.astype(train_dtypes)\n",
    "df_train_1_10000000 = df_train_1_10000000.astype(train_dtypes)\n",
    "\n",
    "#Check dtypes\n",
    "print('df_train_1_10: \\n', df_train_1_10.dtypes)\n",
    "print('df_train_1_1000: \\n', df_train_1_1000.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Dummy Variables\n",
    "\n",
    "`tags` is a compound variable.\n",
    "\n",
    "The entries in the `tags` column in `df_questions` are numerical ids seperated by spaces where each id is a category that corresponds to the subject matter of the question. Many questions have more than one id in `tags`, though some questions only have one. \n",
    "\n",
    "We need to use `Dataframe.get_dummy()` to seperate the compound variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values in tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Profiling Report\n",
    "The Pandas Profiling module is a quick way to get an overview of the data sets. For the largest dataset, we will make a profile report on the subset only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "from pathlib import Path\n",
    "\n",
    "#Define Pandas Profile Report save path\n",
    "pandas_profiling_report_dir = Path('../reports')\n",
    "\n",
    "#Generate Pandas Profiling Report - may be slow running if using the largest subsets of the data\n",
    "\n",
    "report_lectures= ProfileReport(df_lectures, sort='None', html={'style':{'full_width': True}}, progress_bar=False)\n",
    "report_questions = ProfileReport(df_questions, sort='None', html={'style':{'full_width': True}}, progress_bar=False)\n",
    "report_train_1_100000= ProfileReport(df_train_1_100000, sort='None', html={'style':{'full_width': True}}, progress_bar=False)\n",
    "\n",
    "#Save reports to file\n",
    "report_lectures.to_file(pandas_profiling_report_dir / 'lectures.html')\n",
    "report_questions.to_file(pandas_profiling_report_dir / 'questions.html')\n",
    "report_train_1_100000.to_file(pandas_profiling_report_dir / 'train_1_100000.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Pandas Profiling reports, we can see that the data is pretty clean, as expected for a Kaggle dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtXv1bctzDw8"
   },
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lecture_id    0\n",
       "tag           0\n",
       "part          0\n",
       "type_of       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lectures.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_id       0\n",
       "bundle_id         0\n",
       "correct_answer    0\n",
       "part              0\n",
       "tags              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id                                  0\n",
       "timestamp                               0\n",
       "user_id                                 0\n",
       "content_id                              0\n",
       "content_type_id                         0\n",
       "task_container_id                       0\n",
       "user_answer                             0\n",
       "answered_correctly                      0\n",
       "prior_question_elapsed_time       2351538\n",
       "prior_question_had_explanation     392506\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `lectures` has no missing data, `questions` has one missing tag, and `train` has 2 million (about 2%) missing `prior_question_elapsed_time` entries and less than 1% missing entries in `prior_question_had_explanation`. Based on the explanation of the data from Kaggle, we can conclude that this missing data is normal. Nothing should be discard or imputed at this stage.\n",
    "\n",
    "Note that the target variable, `answered_correctly`, has no missing data. This is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of duplicates in df_lectures:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Fraction of duplicates in df_lectures:\")\n",
    "df_lectures.duplicated().sum() / len(df_lectures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of duplicates in df_lectures:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Fraction of duplicates in df_questions:\")\n",
    "df_questions.duplicated().sum() / len(df_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of duplicates in df_train (df_train_1_100):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Fraction of duplicates in df_train (df_train_1_100):\")\n",
    "df_train_1_100.duplicated().sum() / len(df_train_1_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, as this Kaggle competition dataset, which are known to be fairly clean, there is no duplicated entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "Capstone 2 - Data Cleaning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
